{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "from sklearn.mixture import GaussianMixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class GMM:\n",
    "    \"\"\" Gaussian Mixture Model\n",
    "    \n",
    "    Parameters\n",
    "    -----------\n",
    "        k: int , number of gaussian distributions\n",
    "        \n",
    "        seed: int, will be randomly set if None\n",
    "        \n",
    "        max_iter: int, number of iterations to run algorithm, default: 200\n",
    "        \n",
    "    Attributes\n",
    "    -----------\n",
    "       centroids: array, k, number_features\n",
    "       \n",
    "       cluster_labels: label for each data point\n",
    "       \n",
    "    \"\"\"\n",
    "    def __init__(self, C, n_runs):\n",
    "        self.C = C # number of Guassians/clusters\n",
    "        self.n_runs = n_runs\n",
    "        \n",
    "    \n",
    "    def get_params(self):\n",
    "        return (self.mu, self.pi, self.sigma)\n",
    "    \n",
    "    \n",
    "        \n",
    "    def calculate_mean_covariance(self, X, prediction):\n",
    "        \"\"\"Calculate means and covariance of different\n",
    "            clusters from k-means prediction\n",
    "        \n",
    "        Parameters:\n",
    "        ------------\n",
    "        prediction: cluster labels from k-means\n",
    "        \n",
    "        X: N*d numpy array data points \n",
    "        \n",
    "        Returns:\n",
    "        -------------\n",
    "        intial_means: for E-step of EM algorithm\n",
    "        \n",
    "        intial_cov: for E-step of EM algorithm\n",
    "        \n",
    "        \"\"\"\n",
    "        d = X.shape[1]\n",
    "        labels = np.unique(prediction)\n",
    "        self.initial_means = np.zeros((self.C, d))\n",
    "        self.initial_cov = np.zeros((self.C, d, d))\n",
    "        self.initial_pi = np.zeros(self.C)\n",
    "        \n",
    "        counter=0\n",
    "        for label in labels:\n",
    "            ids = np.where(prediction == label) # returns indices\n",
    "            self.initial_pi[counter] = len(ids[0]) / X.shape[0]\n",
    "            self.initial_means[counter,:] = np.mean(X[ids], axis = 0)\n",
    "            de_meaned = X[ids] - self.initial_means[counter,:]\n",
    "            Nk = X[ids].shape[0] # number of data points in current gaussian\n",
    "            self.initial_cov[counter,:, :] = np.dot(self.initial_pi[counter] * de_meaned.T, de_meaned) / Nk\n",
    "            counter+=1\n",
    "        assert np.sum(self.initial_pi) == 1    \n",
    "            \n",
    "        return (self.initial_means, self.initial_cov, self.initial_pi)\n",
    "    \n",
    "    def _initialise_parameters(self, X):\n",
    "        \"\"\"Implement k-means to find starting\n",
    "            parameter values.\n",
    "        Parameters:\n",
    "        ------------\n",
    "        X: numpy array of data points\n",
    "        \n",
    "        Returns:\n",
    "        ----------\n",
    "        tuple containing initial means and covariance\n",
    "        \n",
    "        _initial_means: numpy array: (C*d)\n",
    "        \n",
    "        _initial_cov: numpy array: (C,d*d)\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        n_clusters = self.C\n",
    "        kmeans = KMeans(n_clusters= n_clusters, init=\"k-means++\", max_iter=500, algorithm = 'auto')\n",
    "        fitted = kmeans.fit(X)\n",
    "        prediction = kmeans.predict(X)\n",
    "        self._initial_means, self._initial_cov, self._initial_pi = self.calculate_mean_covariance(X, prediction)\n",
    "        \n",
    "        \n",
    "        return (self._initial_means, self._initial_cov, self._initial_pi)\n",
    "\n",
    "    def _m_step(self, X, gamma):\n",
    "        \"\"\"Performs M-step of the GMM\n",
    "        We need to update our priors, our means\n",
    "        and our covariance matrix.\n",
    "        Parameters:\n",
    "        -----------\n",
    "        X: (N x d), data \n",
    "        gamma: (N x C), posterior distribution of lower bound \n",
    "        Returns:\n",
    "        ---------\n",
    "        pi: (C)\n",
    "        mu: (C x d)\n",
    "        sigma: (C x d x d)\n",
    "        \"\"\"\n",
    "        N = X.shape[0] # number of objects\n",
    "        C = self.gamma.shape[1] # number of clusters\n",
    "        d = X.shape[1] # dimension of each object\n",
    "\n",
    "        # responsibilities for each gaussian\n",
    "        self.pi = np.mean(self.gamma, axis = 0)\n",
    "\n",
    "        self.mu = np.dot(self.gamma.T, X) / np.sum(self.gamma, axis = 0)[:,np.newaxis]\n",
    "\n",
    "        for c in range(C):\n",
    "            x = X - self.mu[c, :] # (N x d)\n",
    "            \n",
    "            gamma_diag = np.diag(self.gamma[:,c])\n",
    "            x_mu = np.matrix(x)\n",
    "            gamma_diag = np.matrix(gamma_diag)\n",
    "\n",
    "            sigma_c = x.T * gamma_diag * x\n",
    "            self.sigma[c,:,:]=(sigma_c) / np.sum(self.gamma, axis = 0)[:,np.newaxis][c]\n",
    "\n",
    "        return self.pi, self.mu, self.sigma\n",
    "    \n",
    "    \n",
    "    def _compute_loss_function(self, X, pi, mu, sigma):\n",
    "        \"\"\"Computes lower bound loss function\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X: (N x d), data \n",
    "        \n",
    "        Returns:\n",
    "        ---------\n",
    "        pi: (C)\n",
    "        mu: (C x d)\n",
    "        sigma: (C x d x d)\n",
    "        \"\"\"\n",
    "        N = X.shape[0]\n",
    "        C = self.gamma.shape[1]\n",
    "        self.loss = np.zeros((N, C))\n",
    "\n",
    "        for c in range(C):\n",
    "            dist = mvn(self.mu[c], self.sigma[c],allow_singular=True)\n",
    "            self.loss[:,c] = self.gamma[:,c] * (np.log(self.pi[c]+0.00001)+dist.logpdf(X)-np.log(self.gamma[:,c]+0.000001))\n",
    "        self.loss = np.sum(self.loss)\n",
    "        return self.loss\n",
    "\n",
    "    def fit(self, X):\n",
    "        \"\"\"Compute the E-step and M-step and\n",
    "            Calculates the lowerbound\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X: (N x d), data \n",
    "        \n",
    "        Returns:\n",
    "        ----------\n",
    "        instance of GMM\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        d = X.shape[1]\n",
    "        self.mu, self.sigma, self.pi =  self._initialise_parameters(X)\n",
    "        \n",
    "        try:\n",
    "            for run in range(self.n_runs):  \n",
    "                self.gamma  = self._e_step(X, self.mu, self.pi, self.sigma)\n",
    "                self.pi, self.mu, self.sigma = self._m_step(X, self.gamma)\n",
    "                loss = self._compute_loss_function(X, self.pi, self.mu, self.sigma)\n",
    "                \n",
    "                if run % 10 == 0:\n",
    "                    print(\"Iteration: %d Loss: %0.6f\" %(run, loss))\n",
    "\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            \n",
    "        \n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Returns predicted labels using Bayes Rule to\n",
    "        Calculate the posterior distribution\n",
    "        \n",
    "        Parameters:\n",
    "        -------------\n",
    "        X: N*d numpy array\n",
    "        \n",
    "        Returns:\n",
    "        ----------\n",
    "        labels: predicted cluster based on \n",
    "        highest responsibility gamma.\n",
    "        \n",
    "        \"\"\"\n",
    "        labels = np.zeros((X.shape[0], self.C))\n",
    "        \n",
    "        for c in range(self.C):\n",
    "            labels [:,c] = self.pi[c] * mvn.pdf(X, self.mu[c,:], self.sigma[c])\n",
    "        labels  = labels.argmax(1)\n",
    "        return labels \n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Returns predicted labels\n",
    "        \n",
    "        Parameters:\n",
    "        -------------\n",
    "        X: N*d numpy array\n",
    "        \n",
    "        Returns:\n",
    "        ----------\n",
    "        labels: predicted cluster based on \n",
    "        highest responsibility gamma.\n",
    "        \n",
    "        \"\"\"\n",
    "        post_proba = np.zeros((X.shape[0], self.C))\n",
    "        \n",
    "        for c in range(self.C):\n",
    "            # Posterior Distribution using Bayes Rule\n",
    "            post_proba[:,c] = self.pi[c] * mvn.pdf(X, self.mu[c,:], self.sigma[c])\n",
    "    \n",
    "        return post_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-12-b03b81ba3b66>, line 19)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-12-b03b81ba3b66>\"\u001b[0;36m, line \u001b[0;32m19\u001b[0m\n\u001b[0;31m    draw_ellipse(pos, covar, alpha = w)\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "model = GMM(3, n_runs = 30)\n",
    "\n",
    "fitted_values = model.fit(Y_sklearn)\n",
    "predicted_values = model.predict(Y_sklearn)\n",
    "\n",
    "# # compute centers as point of highest density of distribution\n",
    "centers = np.zeros((3,2))\n",
    "for i in range(model.C):\n",
    "    density = mvn(cov=model.sigma[i], mean=model.mu[i]).logpdf(Y_sklearn)\n",
    "    centers[i, :] = Y_sklearn[np.argmax(density)]\n",
    "    \n",
    "plt.figure(figsize = (10,8))\n",
    "plt.scatter(Y_sklearn[:, 0], Y_sklearn[:, 1],c=predicted_values ,s=50, cmap='viridis', zorder=1)\n",
    "\n",
    "plt.scatter(centers[:, 0], centers[:, 1],c='black', s=300, alpha=0.5, zorder=2);\n",
    "\n",
    "w_factor = 0.2 / model.pi.max()\n",
    "for pos, covar, w in zip(model.mu, model.sigma, model.pi):\n",
    "draw_ellipse(pos, covar, alpha = w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
