{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../input'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-73659b607554>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memail\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../input\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# Any results you write to the current directory are saved as output.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../input'"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from scipy.stats import multivariate_normal as mvn\n",
    "import math\n",
    "\n",
    "from numpy.linalg import slogdet, det, solve\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "import time\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.mixture.base import BaseMixture\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "import os, sys, email,re\n",
    "from nltk.corpus import stopwords\n",
    "#print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0874d78483ef758e105cc7214aa7bae3f65984d7"
   },
   "outputs": [],
   "source": [
    "samples = np.load('../input/samples/samples.npz')\n",
    "X = samples['data']\n",
    "pi0 = samples['pi0']\n",
    "mu0 = samples['mu0']\n",
    "sigma0 = samples['sigma0']\n",
    "plt.scatter(X[:, 0], X[:, 1], c='grey', s=30)\n",
    "plt.axis('equal')\n",
    "plt.show()\n",
    "print(pi0, mu0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "48ae0a0454b2b70b6e3b6e0796b3a6caa532faa2"
   },
   "source": [
    "# GMM should produce something similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "883efab9d215144ad8eef6d411a225d2134a21c5"
   },
   "outputs": [],
   "source": [
    "kmeans_test = KMeans(n_clusters= 3, init=\"k-means++\", max_iter=500, algorithm = 'auto')\n",
    "fitted = kmeans_test.fit(X)\n",
    "prediction = kmeans_test.predict(X)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=prediction, s=30)\n",
    "plt.axis('equal')\n",
    "plt.show()\n",
    "\n",
    "kmeans_test.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "19f44c4e86f573544fe4c46b7666e5f18088a4d4"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,8))\n",
    "from scipy.spatial.distance import cdist\n",
    "def plot_kmeans(kmeans, X, n_clusters=4, rseed=0, ax=None):\n",
    "    labels = kmeans.fit_predict(X)\n",
    "\n",
    "    # plot the input data\n",
    "    ax = ax or plt.gca()\n",
    "    ax.axis('equal')\n",
    "    ax.scatter(X[:, 0], X[:, 1], c=labels, s=40, cmap='viridis', zorder=2)\n",
    "\n",
    "    # plot the representation of the KMeans model\n",
    "    centers = kmeans.cluster_centers_\n",
    "    radii = [cdist(X[labels == i], [center]).max()\n",
    "             for i, center in enumerate(centers)]\n",
    "    for c, r in zip(centers, radii):\n",
    "        ax.add_patch(plt.Circle(c, r, fc='#CCCCCC', lw=3, alpha=0.5, zorder=1))\n",
    "        \n",
    "plot_kmeans(kmeans_test, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b662401740fc9a0c9690be0d19e48548be0d24ee"
   },
   "source": [
    "# GMM sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e62caa139068ffe2a162cc05805b4501b9938adf"
   },
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "gmm = GaussianMixture(n_components=3).fit(X)\n",
    "labels = gmm.predict(X)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=labels, s=40, cmap='viridis');\n",
    "probs = gmm.predict_proba(X)\n",
    "# print(probs[:5].round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c6039b3e36a59fa9ec4447fcaf60624dcaf96d1f"
   },
   "outputs": [],
   "source": [
    "# print(gmm._get_parameters()[0])\n",
    "# print(gmm._get_parameters()[1])\n",
    "#gmm.lower_bound_\n",
    "# kmeans mean values\n",
    "# array([[1.20514208, 5.82885457],\n",
    "#        [0.9733235 , 0.94371856],\n",
    "#        [6.40546402, 4.50975916]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d7a1695b416890a82b99c824540e28bdae201ec8"
   },
   "source": [
    "# Test Functions from class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "03b90668c7c6e05986c939982060608b6d5e20dd"
   },
   "outputs": [],
   "source": [
    "def calculate_mean_covariance(X, prediction):\n",
    "    C = 3\n",
    "    d = X.shape[1]\n",
    "    labels = np.unique(prediction)\n",
    "    initial_means = np.zeros((C, d))\n",
    "    initial_cov = np.zeros((C, d, d))\n",
    "    initial_pi = np.zeros(C)\n",
    "        \n",
    "    counter=0\n",
    "    for label in sorted(labels):\n",
    "        ids = np.where(prediction == label) # returns indices\n",
    "        initial_pi[counter] = len(ids[0]) / X.shape[0] \n",
    "        initial_means[counter,:] = np.mean(X[ids], axis = 0)\n",
    "        de_meaned = X[ids] - initial_means[counter,:]\n",
    "        Nk = X[ids].shape[0]\n",
    "        initial_cov[counter,:, :] = np.dot(initial_pi[counter] * de_meaned.T, de_meaned) / Nk\n",
    "        counter+=1\n",
    "    assert np.sum(initial_pi) == 1\n",
    "    return (initial_means, initial_cov, initial_pi)\n",
    "    \n",
    "n_clusters = 3\n",
    "kmeans = KMeans(n_clusters= n_clusters, max_iter=500, algorithm = 'auto')\n",
    "fitted = kmeans.fit(X)\n",
    "prediction = kmeans.predict(X)\n",
    "\n",
    "m, c, pi = calculate_mean_covariance(X, prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7463eeda8534ff2dfa093c58217e57891a4e4257"
   },
   "source": [
    "# New E-Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4728e6fe58255084e0e4106a5d5a2977ac6d18ce"
   },
   "outputs": [],
   "source": [
    "class GMM:\n",
    "    \"\"\" Gaussian Mixture Model\n",
    "    \n",
    "    Parameters\n",
    "    -----------\n",
    "        k: int , number of gaussian distributions\n",
    "        \n",
    "        seed: int, will be randomly set if None\n",
    "        \n",
    "        max_iter: int, number of iterations to run algorithm, default: 200\n",
    "        \n",
    "    Attributes\n",
    "    -----------\n",
    "       centroids: array, k, number_features\n",
    "       \n",
    "       cluster_labels: label for each data point\n",
    "       \n",
    "    \"\"\"\n",
    "    def __init__(self, C, n_runs):\n",
    "        self.C = C # number of Guassians/clusters\n",
    "        self.n_runs = n_runs\n",
    "        \n",
    "    \n",
    "    def get_params(self):\n",
    "        return (self.mu, self.pi, self.sigma)\n",
    "    \n",
    "    \n",
    "        \n",
    "    def calculate_mean_covariance(self, X, prediction):\n",
    "        \"\"\"Calculate means and covariance of different\n",
    "            clusters from k-means prediction\n",
    "        \n",
    "        Parameters:\n",
    "        ------------\n",
    "        prediction: cluster labels from k-means\n",
    "        \n",
    "        X: N*d numpy array data points \n",
    "        \n",
    "        Returns:\n",
    "        -------------\n",
    "        intial_means: for E-step of EM algorithm\n",
    "        \n",
    "        intial_cov: for E-step of EM algorithm\n",
    "        \n",
    "        \"\"\"\n",
    "        d = X.shape[1]\n",
    "        labels = np.unique(prediction)\n",
    "        self.initial_means = np.zeros((self.C, d))\n",
    "        self.initial_cov = np.zeros((self.C, d, d))\n",
    "        self.initial_pi = np.zeros(self.C)\n",
    "        \n",
    "        counter=0\n",
    "        for label in labels:\n",
    "            ids = np.where(prediction == label) # returns indices\n",
    "            self.initial_pi[counter] = len(ids[0]) / X.shape[0]\n",
    "            self.initial_means[counter,:] = np.mean(X[ids], axis = 0)\n",
    "            de_meaned = X[ids] - self.initial_means[counter,:]\n",
    "            Nk = X[ids].shape[0] # number of data points in current gaussian\n",
    "            self.initial_cov[counter,:, :] = np.dot(self.initial_pi[counter] * de_meaned.T, de_meaned) / Nk\n",
    "            counter+=1\n",
    "        assert np.sum(self.initial_pi) == 1    \n",
    "            \n",
    "        return (self.initial_means, self.initial_cov, self.initial_pi)\n",
    "    \n",
    "    \n",
    "    \n",
    "    def _initialise_parameters(self, X):\n",
    "        \"\"\"Implement k-means to find starting\n",
    "            parameter values.\n",
    "            https://datascience.stackexchange.com/questions/11487/how-do-i-obtain-the-weight-and-variance-of-a-k-means-cluster\n",
    "\n",
    "        Parameters:\n",
    "        ------------\n",
    "        X: numpy array of data points\n",
    "        \n",
    "        Returns:\n",
    "        ----------\n",
    "        tuple containing initial means and covariance\n",
    "        \n",
    "        _initial_means: numpy array: (C*d)\n",
    "        \n",
    "        _initial_cov: numpy array: (C,d*d)\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        n_clusters = self.C\n",
    "        kmeans = KMeans(n_clusters= n_clusters, init=\"k-means++\", max_iter=500, algorithm = 'auto')\n",
    "        fitted = kmeans.fit(X)\n",
    "        prediction = kmeans.predict(X)\n",
    "        self._initial_means, self._initial_cov, self._initial_pi = self.calculate_mean_covariance(X, prediction)\n",
    "        \n",
    "        \n",
    "        return (self._initial_means, self._initial_cov, self._initial_pi)\n",
    "            \n",
    "        \n",
    "        \n",
    "    def _e_step(self, X, pi, mu, sigma):\n",
    "        \"\"\"Performs E-step on GMM model\n",
    "\n",
    "        Parameters:\n",
    "        ------------\n",
    "        X: (N x d), data points, m: no of features\n",
    "        pi: (C), weights of mixture components\n",
    "        mu: (C x d), mixture component means\n",
    "        sigma: (C x d x d), mixture component covariance matrices\n",
    "\n",
    "        Returns:\n",
    "        ----------\n",
    "        gamma: (N x C), probabilities of clusters for objects\n",
    "        \"\"\"\n",
    "        N = X.shape[0] \n",
    "        self.gamma = np.zeros((N, self.C))\n",
    "\n",
    "        const_c = np.zeros(self.C)\n",
    "        \n",
    "        \n",
    "        self.mu = self.mu if self._initial_means is None else self._initial_means\n",
    "        self.pi = self.pi if self._initial_pi is None else self._initial_pi\n",
    "        self.sigma = self.sigma if self._initial_cov is None else self._initial_cov\n",
    "\n",
    "        for c in range(self.C):\n",
    "            # Posterior Distribution using Bayes Rule\n",
    "            self.gamma[:,c] = self.pi[c] * mvn.pdf(X, self.mu[c,:], self.sigma[c])\n",
    "\n",
    "        # normalize across columns to make a valid probability\n",
    "        gamma_norm = np.sum(self.gamma, axis=1)[:,np.newaxis]\n",
    "        self.gamma /= gamma_norm\n",
    "\n",
    "        return self.gamma\n",
    "    \n",
    "    \n",
    "    def _m_step(self, X, gamma):\n",
    "        \"\"\"Performs M-step of the GMM\n",
    "        We need to update our priors, our means\n",
    "        and our covariance matrix.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        X: (N x d), data \n",
    "        gamma: (N x C), posterior distribution of lower bound \n",
    "\n",
    "        Returns:\n",
    "        ---------\n",
    "        pi: (C)\n",
    "        mu: (C x d)\n",
    "        sigma: (C x d x d)\n",
    "        \"\"\"\n",
    "        N = X.shape[0] # number of objects\n",
    "        C = self.gamma.shape[1] # number of clusters\n",
    "        d = X.shape[1] # dimension of each object\n",
    "\n",
    "        # responsibilities for each gaussian\n",
    "        self.pi = np.mean(self.gamma, axis = 0)\n",
    "\n",
    "        self.mu = np.dot(self.gamma.T, X) / np.sum(self.gamma, axis = 0)[:,np.newaxis]\n",
    "\n",
    "        for c in range(C):\n",
    "            x = X - self.mu[c, :] # (N x d)\n",
    "            \n",
    "            gamma_diag = np.diag(self.gamma[:,c])\n",
    "            x_mu = np.matrix(x)\n",
    "            gamma_diag = np.matrix(gamma_diag)\n",
    "\n",
    "            sigma_c = x.T * gamma_diag * x\n",
    "            self.sigma[c,:,:]=(sigma_c) / np.sum(self.gamma, axis = 0)[:,np.newaxis][c]\n",
    "\n",
    "        return self.pi, self.mu, self.sigma\n",
    "    \n",
    "    \n",
    "    def _compute_loss_function(self, X, pi, mu, sigma):\n",
    "        \"\"\"Computes lower bound loss function\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X: (N x d), data \n",
    "        \n",
    "        Returns:\n",
    "        ---------\n",
    "        pi: (C)\n",
    "        mu: (C x d)\n",
    "        sigma: (C x d x d)\n",
    "        \"\"\"\n",
    "        N = X.shape[0]\n",
    "        C = self.gamma.shape[1]\n",
    "        self.loss = np.zeros((N, C))\n",
    "\n",
    "        for c in range(C):\n",
    "            dist = mvn(self.mu[c], self.sigma[c],allow_singular=True)\n",
    "            self.loss[:,c] = self.gamma[:,c] * (np.log(self.pi[c]+0.00001)+dist.logpdf(X)-np.log(self.gamma[:,c]+0.000001))\n",
    "        self.loss = np.sum(self.loss)\n",
    "        return self.loss\n",
    "    \n",
    "    \n",
    "    \n",
    "    def fit(self, X):\n",
    "        \"\"\"Compute the E-step and M-step and\n",
    "            Calculates the lowerbound\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X: (N x d), data \n",
    "        \n",
    "        Returns:\n",
    "        ----------\n",
    "        instance of GMM\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        d = X.shape[1]\n",
    "        self.mu, self.sigma, self.pi =  self._initialise_parameters(X)\n",
    "        \n",
    "        try:\n",
    "            for run in range(self.n_runs):  \n",
    "                self.gamma  = self._e_step(X, self.mu, self.pi, self.sigma)\n",
    "                self.pi, self.mu, self.sigma = self._m_step(X, self.gamma)\n",
    "                loss = self._compute_loss_function(X, self.pi, self.mu, self.sigma)\n",
    "                \n",
    "                if run % 10 == 0:\n",
    "                    print(\"Iteration: %d Loss: %0.6f\" %(run, loss))\n",
    "\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            \n",
    "        \n",
    "        return self\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Returns predicted labels using Bayes Rule to\n",
    "        Calculate the posterior distribution\n",
    "        \n",
    "        Parameters:\n",
    "        -------------\n",
    "        X: ?*d numpy array\n",
    "        \n",
    "        Returns:\n",
    "        ----------\n",
    "        labels: predicted cluster based on \n",
    "        highest responsibility gamma.\n",
    "        \n",
    "        \"\"\"\n",
    "        labels = np.zeros((X.shape[0], self.C))\n",
    "        \n",
    "        for c in range(self.C):\n",
    "            labels [:,c] = self.pi[c] * mvn.pdf(X, self.mu[c,:], self.sigma[c])\n",
    "        labels  = labels .argmax(1)\n",
    "        return labels \n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Returns predicted labels\n",
    "        \n",
    "        Parameters:\n",
    "        -------------\n",
    "        X: N*d numpy array\n",
    "        \n",
    "        Returns:\n",
    "        ----------\n",
    "        labels: predicted cluster based on \n",
    "        highest responsibility gamma.\n",
    "        \n",
    "        \"\"\"\n",
    "        post_proba = np.zeros((X.shape[0], self.C))\n",
    "        \n",
    "        for c in range(self.C):\n",
    "            # Posterior Distribution using Bayes Rule, try and vectorise\n",
    "            post_proba[:,c] = self.pi[c] * mvn.pdf(X, self.mu[c,:], self.sigma[c])\n",
    "    \n",
    "        return post_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "77e4cb8868820f2a9b122821aff2f10ce14027bc"
   },
   "source": [
    "# Test GMM class\n",
    "- class working \n",
    "- same as sklearn implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "335fd741870199f110558f56b076ad28bf047b21"
   },
   "outputs": [],
   "source": [
    "model = GMM(3, n_runs = 100)\n",
    "\n",
    "fitted_values = model.fit(X)\n",
    "\n",
    "predicted_values = model.predict(X)\n",
    "# compute centers as point of highest density of distribution\n",
    "centers = np.zeros((3,2))\n",
    "for i in range(model.C):\n",
    "    density = mvn(cov=model.sigma[i], mean=model.mu[i]).logpdf(X)\n",
    "    centers[i, :] = X[np.argmax(density)]\n",
    "    \n",
    "plt.figure(figsize = (10,8))\n",
    "plt.scatter(X[:, 0], X[:, 1],c=predicted_values ,s=50, cmap='viridis')\n",
    "\n",
    "plt.scatter(centers[:, 0], centers[:, 1],c='black', s=300, alpha=0.6);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a210dfd496eba15c2e6a93c175c5b2f9b682b4a8"
   },
   "source": [
    "# Compare sklearn and my own and test predict method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4612033776bc5f5f4e3230f16cb782898e479baa"
   },
   "outputs": [],
   "source": [
    "# print(\"initial means: \", model._initial_means)\n",
    "# print('--------------------------')\n",
    "# print(\"initial pi: \", model._initial_pi)\n",
    "# print('--------------------------')\n",
    "# print('GMM means: ', model.get_params()[1])\n",
    "# print('--------------------------')\n",
    "# print('GMM pi: ', model.get_params()[0])\n",
    "# print('--------------------------')\n",
    "# print('sklearn GMM means: ', gmm._get_parameters()[1])\n",
    "# print('--------------------------')\n",
    "# print('sklearn GMM pi: ', gmm._get_parameters()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "237e5aee7327fb9bc4421b4fc7aa7c39b6c6f98d"
   },
   "source": [
    "# Plot clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "35daa5a8fc5de7976fc708f0be556b3caace0be3"
   },
   "outputs": [],
   "source": [
    "# Credit to python data science handbook for the code to plot these distributions\n",
    "from matplotlib.patches import Ellipse\n",
    "\n",
    "def draw_ellipse(position, covariance, ax=None, **kwargs):\n",
    "    \"\"\"Draw an ellipse with a given position and covariance\"\"\"\n",
    "    ax = ax or plt.gca()\n",
    "    \n",
    "    # Convert covariance to principal axes\n",
    "    if covariance.shape == (2, 2):\n",
    "        U, s, Vt = np.linalg.svd(covariance)\n",
    "        angle = np.degrees(np.arctan2(U[1, 0], U[0, 0]))\n",
    "        width, height = 2 * np.sqrt(s)\n",
    "    else:\n",
    "        angle = 0\n",
    "        width, height = 2 * np.sqrt(covariance)\n",
    "    \n",
    "    # Draw the Ellipse\n",
    "    for nsig in range(1, 4):\n",
    "        ax.add_patch(Ellipse(position, nsig * width, nsig * height,\n",
    "                             angle, **kwargs))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0fa540f751aa42023a7593c65541efe5a72f0aa1"
   },
   "source": [
    "# Draw Distributions around GMM clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8eb1e661860efe14ef86fbd12df0c56784ca28e3"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,8))\n",
    "plt.scatter(X[:, 0], X[:, 1],c=predicted_values ,s=50, cmap='viridis')\n",
    "plt.scatter(centers[:, 0], centers[:, 1],c='black', s=300, alpha=0.6);\n",
    "\n",
    "w_factor = 0.2 / model.pi.max()\n",
    "for pos, covar, w in zip(model.mu, model.sigma, model.pi):\n",
    "    draw_ellipse(pos, covar, alpha=w * w_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "37a0a26dd125206377f6c7789bb69fa5fe9ca1a2"
   },
   "outputs": [],
   "source": [
    "def E_step(X, pi, mu, sigma):\n",
    "    \"\"\"Performs E-step on GMM model\n",
    "\n",
    "        Parameters:\n",
    "        ------------\n",
    "        X: (N x m), data points, m: no of features\n",
    "        pi: (C), weights of mixture components\n",
    "        mu: (C x m), mixture component means\n",
    "        sigma: (C x m x m), mixture component covariance matrices\n",
    "\n",
    "        Returns:\n",
    "        ----------\n",
    "        gamma: (N x C), probabilities of clusters for objects\n",
    "        \"\"\"\n",
    "    \n",
    "    N = X.shape[0] \n",
    "    C = pi0.shape[0] # number of clusters\n",
    "    gamma = np.zeros((N, C))\n",
    "\n",
    "    const_c = np.zeros(C)\n",
    "\n",
    "    for c in range(C):\n",
    "#         pi_c = pi0[c]\n",
    "#         mu_c = mu0[c, :] \n",
    "#         sigma_c = sigma0[c] \n",
    "\n",
    "        # Posterior Distribution using Bayes Rule\n",
    "        gamma[:,c] = pi0[c] * mvn.pdf(X, mu0[c,:], sigma0[c])\n",
    "\n",
    "    # normalize across columns to make a valid probability\n",
    "    gamma_norm = np.sum(gamma, axis=1)[:,np.newaxis]\n",
    "    gamma /= gamma_norm\n",
    "\n",
    "    return gamma\n",
    "\n",
    "gamma = E_step(X, pi0, mu0, sigma0)\n",
    "print(np.sum(gamma, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a179421a7a579ec21193df0c297bc049f2f425c8"
   },
   "source": [
    "# M Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ddb4dfbb110c920ea2aa76a24137ac90593bef0d"
   },
   "outputs": [],
   "source": [
    "def M_step(X, gamma):\n",
    "    \"\"\"Performs M-step of the GMM\n",
    "    We need to update our priors, our means\n",
    "    and our covariance matrix.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X: (N x d), data \n",
    "    gamma: (N x C), posterior distribution of lower bound \n",
    "    \n",
    "    Returns:\n",
    "    ---------\n",
    "    pi: (C)\n",
    "    mu: (C x d)\n",
    "    sigma: (C x d x d)\n",
    "    \"\"\"\n",
    "    N = X.shape[0] # number of objects\n",
    "    C = gamma.shape[1] # number of clusters\n",
    "    d = X.shape[1] # dimension of each object\n",
    "\n",
    "    ### YOUR CODE HERE\n",
    "    mu = np.zeros((C, d))\n",
    "    sigma = np.zeros((C, d, d))\n",
    "    \n",
    "    # responsibilities for each gaussian\n",
    "    pi = np.mean(gamma, axis = 0)\n",
    "    mu = np.dot(gamma.T, X) / np.sum(gamma, axis = 0)[:,np.newaxis]\n",
    "     \n",
    "    for c in range(C): # for each Gaussian\n",
    "        x_mu = X - mu[c, :] # (N x d)\n",
    "        \n",
    "        gamma_diag = np.diag(gamma[:,c])\n",
    "        x_mu = np.matrix(x_mu)\n",
    "        gamma_diag = np.matrix(gamma_diag)\n",
    "        \n",
    "        sigma_c = x_mu.T * gamma_diag * x_mu\n",
    "        sigma[c,:,:]=(sigma_c) / np.sum(gamma, axis = 0)[:,np.newaxis][c]\n",
    "    \n",
    "    return pi, mu, sigma\n",
    "pi, mu, sigma = M_step(X, gamma)\n",
    "print(pi, mu, sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7cabb3d25a1f0f26273e3aca274a93fb4eb8d61b"
   },
   "source": [
    "# Variational Lower Bound\n",
    "$$\\mathcal{L} = \\sum_{n=1}^{N} \\sum_{k=1}^{K} \\mathbb{E}[z_{n, k}] (\\log \\pi_k + \\log \\mathcal{N}(x_n | \\mu_k, \\sigma_k)) - \\sum_{n=1}^{N} \\sum_{k=1}^{K} \\mathbb{E}[z_{n, k}] \\log \\mathbb{E}[z_{n, k}]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9a707495e8dc658f1770a8066fe0ad602b145570"
   },
   "outputs": [],
   "source": [
    "def compute_loss_function(X, gamma, pi, mu, sigma):\n",
    "    N = X.shape[0]\n",
    "    C = gamma.shape[1]\n",
    "    loss = np.zeros((N,C))\n",
    "    \n",
    "    for c in range(C):\n",
    "        dist = mvn(mu[c], sigma[c],allow_singular=True)\n",
    "        loss[:,c] = gamma[:,c] * (np.log(pi[c]+0.00001)+dist.logpdf(X)-np.log(gamma[:,c]+0.000001))\n",
    "\n",
    "    return np.sum(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c54a68c0a3a6f447836c43eb0cd820aea307c4cd"
   },
   "outputs": [],
   "source": [
    "compute_loss_function(X, gamma, pi, mu, sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7f56a3676e67386b1083bfa58b7601ca65bc66c6"
   },
   "source": [
    "# Test all functions\n",
    "- seem to be correct. Class implmentation doesnt give same answer\n",
    "- Could be because I have an incorrect initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b4ad2c4b0d6c9bcb124569bf747a232f74fc4255"
   },
   "outputs": [],
   "source": [
    "pi, mu, sigma = pi0, mu0, sigma0\n",
    "gamma = E_step(X, pi, mu, sigma)\n",
    "pi, mu, sigma = M_step(X, gamma)\n",
    "loss = compute_loss_function(X, gamma, pi, mu, sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "aacf849fc91bebc04a99f34f19f661a989aa7a98"
   },
   "source": [
    "# Test on Enron data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "01168ca295c2f4e7e7b69787384a91ffe4256471"
   },
   "source": [
    "# Read in Data and Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8afa023c4fd5416ad1bc4d6cc0d4ac24995ed4e4"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../input/enron-email-dataset/emails.csv',nrows = 35000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4ff343f85c5a89869f7f49e8ea3dcad283824f4d"
   },
   "outputs": [],
   "source": [
    "# create list of email objects\n",
    "emails = list(map(email.parser.Parser().parsestr,df['message']))\n",
    "\n",
    "# extract headings such as subject, from, to etc..\n",
    "headings  = emails[0].keys()\n",
    "\n",
    "# Goes through each email and grabs info for each key\n",
    "# doc['From'] grabs who sent email in all emails\n",
    "for key in headings:\n",
    "    df[key] = [doc[key] for doc in emails]\n",
    "\n",
    "    \n",
    "##Useful functions\n",
    "def get_raw_text(emails):\n",
    "    email_text = []\n",
    "    for email in emails.walk():\n",
    "        if email.get_content_type() == 'text/plain':\n",
    "            email_text.append(email.get_payload())\n",
    "    return ''.join(email_text)\n",
    "\n",
    "df['body'] = list(map(get_raw_text, emails))\n",
    "df.head()\n",
    "df['user'] = df['file'].map(lambda x: x.split('/')[0])\n",
    "\n",
    "\n",
    "#Unique to and From\n",
    "print('Total number of emails: %d' %len(df))\n",
    "print('------------')\n",
    "print('Number of unique received: %d '%df['To'].nunique())\n",
    "print('------------')\n",
    "print('Number of unique Sent: %d '%df['From'].nunique())\n",
    "\n",
    "\n",
    "def clean_column(data):\n",
    "    if data is not None:\n",
    "        stopwords_list = stopwords.words('english')\n",
    "        #exclusions = ['RE:', 'Re:', 're:']\n",
    "        #exclusions = '|'.join(exclusions)\n",
    "        data =  data.lower()\n",
    "        data = re.sub('re:', '', data)\n",
    "        data = re.sub('-', '', data)\n",
    "        data = re.sub('_', '', data)\n",
    "        # Remove data between square brackets\n",
    "        data =re.sub('\\[[^]]*\\]', '', data)\n",
    "        # removes punctuation\n",
    "        data = re.sub(r'[^\\w\\s]','',data)\n",
    "        data = re.sub(r'\\n',' ',data)\n",
    "        data = re.sub(r'[0-9]+','',data)\n",
    "        # strip html \n",
    "        p = re.compile(r'<.*?>')\n",
    "        data = re.sub(r\"\\'ve\", \" have \", data)\n",
    "        data = re.sub(r\"can't\", \"cannot \", data)\n",
    "        data = re.sub(r\"n't\", \" not \", data)\n",
    "        data = re.sub(r\"I'm\", \"I am\", data)\n",
    "        data = re.sub(r\" m \", \" am \", data)\n",
    "        data = re.sub(r\"\\'re\", \" are \", data)\n",
    "        data = re.sub(r\"\\'d\", \" would \", data)\n",
    "        data = re.sub(r\"\\'ll\", \" will \", data)\n",
    "        data = re.sub('forwarded by phillip k allenhouect on    pm', '',data)\n",
    "        data = re.sub(r\"httpitcappscorpenroncomsrrsauthemaillinkaspidpage\", \"\", data)\n",
    "        \n",
    "        data = p.sub('', data)\n",
    "        if 'forwarded by:' in data:\n",
    "            data = data.split('subject')[1]\n",
    "        data = data.strip()\n",
    "        return data\n",
    "    return 'No Subject'\n",
    "\n",
    "\n",
    "df['Subject_new'] = df['Subject'].apply(clean_column)\n",
    "df['body_new'] = df['body'].apply(clean_column)\n",
    "\n",
    "\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "stopwords = set(STOPWORDS)\n",
    "to_add = ['FW', 'ga', 'httpitcappscorpenroncomsrrsauthemaillinkaspidpage', 'cc', 'aa', 'aaa', 'aaaa',\n",
    "         'hou', 'cc', 'etc', 'subject', 'pm']\n",
    "\n",
    "for i in to_add:\n",
    "    stopwords.add(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "459f5001e576feda674d3e9276f1aef0aabd84ad"
   },
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "85c0ca262dddba739c95544bd0193a907d3e87f5"
   },
   "outputs": [],
   "source": [
    "df['body_new'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fb2909daf33457bf51b41c99123df20d862e253d"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "data = df['body_new']\n",
    "# data.head()\n",
    "\n",
    "tf_idf_vectorizor = TfidfVectorizer(stop_words = stopwords,#tokenizer = tokenize_and_stem,\n",
    "                             max_features = 5000)\n",
    "%time tf_idf = tf_idf_vectorizor.fit_transform(data)\n",
    "tf_idf_norm = normalize(tf_idf)\n",
    "tf_idf_array = tf_idf_norm.toarray()\n",
    "pd.DataFrame(tf_idf_array, columns=tf_idf_vectorizor.get_feature_names()).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4e294e42d5a5cf233e52e9d4d1b750295683416b"
   },
   "source": [
    "# K means sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "42c293bd6976760b881185b9942afe76c542d688"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "n_clusters = 3\n",
    "sklearn_pca = PCA(n_components = 2)\n",
    "Y_sklearn = sklearn_pca.fit_transform(tf_idf_array)\n",
    "kmeans = KMeans(n_clusters= n_clusters, max_iter=600, algorithm = 'auto')\n",
    "%time fitted = kmeans.fit(Y_sklearn)\n",
    "prediction = kmeans.predict(Y_sklearn)\n",
    "\n",
    "plt.scatter(Y_sklearn[:, 0], Y_sklearn[:, 1],c=prediction ,s=50, cmap='viridis')\n",
    "\n",
    "centers2 = fitted.cluster_centers_\n",
    "plt.scatter(centers2[:, 0], centers2[:, 1],c='black', s=300, alpha=0.6);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "05d6b0ce1e80ff01fb9c16bec42dfb04926da8b9"
   },
   "source": [
    "# Draw Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "742bc0f237e29a1131aad5ce17f7e6c35ca2bb35"
   },
   "outputs": [],
   "source": [
    "from matplotlib.patches import Ellipse\n",
    "\n",
    "def draw_ellipse(position, covariance, ax=None, **kwargs):\n",
    "    \"\"\"Draw an ellipse with a given position and covariance\"\"\"\n",
    "    ax = ax or plt.gca()\n",
    "    \n",
    "    # Convert covariance to principal axes\n",
    "    if covariance.shape == (2, 2):\n",
    "        U, s, Vt = np.linalg.svd(covariance)\n",
    "        angle = np.degrees(np.arctan2(U[1, 0], U[0, 0]))\n",
    "        width, height = 2 * np.sqrt(s)\n",
    "    else:\n",
    "        angle = 0\n",
    "        width, height = 2 * np.sqrt(covariance)\n",
    "    \n",
    "    # Draw the Ellipse\n",
    "    for nsig in range(1, 4):\n",
    "        ax.add_patch(Ellipse(position, nsig * width, nsig * height,\n",
    "                             angle, **kwargs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bd9975d37bb3bc88163da417d6f1e4e3fa7c05e8"
   },
   "source": [
    "# GMM sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6cd82179207c77dec0cd2ad749212c843871a47e"
   },
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "sklearn_pca = PCA(n_components = 2)\n",
    "Y_sklearn = sklearn_pca.fit_transform(tf_idf_array)\n",
    "gmm = GaussianMixture(n_components=3, covariance_type='full').fit(Y_sklearn)\n",
    "prediction_gmm = gmm.predict(Y_sklearn)\n",
    "probs = gmm.predict_proba(Y_sklearn)\n",
    "\n",
    "centers = np.zeros((3,2))\n",
    "for i in range(3):\n",
    "    density = mvn(cov=gmm.covariances_[i], mean=gmm.means_[i]).logpdf(Y_sklearn)\n",
    "    centers[i, :] = Y_sklearn[np.argmax(density)]\n",
    "\n",
    "plt.figure(figsize = (10,8))\n",
    "plt.scatter(Y_sklearn[:, 0], Y_sklearn[:, 1],c=prediction_gmm ,s=50, cmap='viridis')\n",
    "plt.scatter(centers[:, 0], centers[:, 1],c='black', s=300, alpha=0.6);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9177f828dcfd4cbe7751b3ff27f45362a4257510"
   },
   "outputs": [],
   "source": [
    "# diag, Gaussians are aligned with th axis\n",
    "plt.figure(figsize = (10,8))\n",
    "plt.scatter(Y_sklearn[:, 0], Y_sklearn[:, 1],c=prediction_gmm ,s=50, cmap='viridis', zorder=1)\n",
    "plt.scatter(centers[:, 0], centers[:, 1],c='black', s=300, alpha=0.6);\n",
    "\n",
    "w_factor = 0.2 / gmm.weights_.max()\n",
    "for pos, covar, w in zip(gmm.means_, gmm.covariances_, gmm.weights_):\n",
    "    draw_ellipse(pos, covar, alpha=w*.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b9a3ffda823d04605c0408eef8ca51a0cca724e2"
   },
   "outputs": [],
   "source": [
    "print(\"GMM weights: \", gmm.weights_)\n",
    "print(\"GMM means: \", gmm.means_)\n",
    "print(\"GMM Covariance: \", gmm.covariances_)\n",
    "print('-----------------------------')\n",
    "print(\"My model weights: \", model.pi)\n",
    "print(\"My model means: \", model.mu)\n",
    "print(\"My model Covariance: \", model.sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "625faee3071cad7cf9274b2619a62cb4e3acc3bd"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,8))\n",
    "from scipy.spatial.distance import cdist\n",
    "def plot_kmeans(kmeans, X, n_clusters=3, rseed=0, ax=None):\n",
    "    labels = kmeans.fit_predict(X)\n",
    "\n",
    "    # plot the input data\n",
    "    ax = ax or plt.gca()\n",
    "    ax.axis('equal')\n",
    "    ax.scatter(X[:, 0], X[:, 1], c=labels, s=40, cmap='viridis', zorder=2)\n",
    "\n",
    "    # plot the representation of the KMeans model\n",
    "    centers = kmeans.cluster_centers_\n",
    "    radii = [cdist(X[labels == i], [center]).max()\n",
    "             for i, center in enumerate(centers)]\n",
    "    for c, r in zip(centers, radii):\n",
    "        ax.add_patch(plt.Circle(c, r, fc='#CCCCCC', lw=3, alpha=0.5, zorder=1))\n",
    "        \n",
    "plot_kmeans(kmeans, Y_sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3ac02af380fdca17177dbd545fdc7257b3a2617f"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,8))\n",
    "plt.scatter(Y_sklearn[:, 0], Y_sklearn[:, 1],c=prediction_gmm ,s=50, cmap='viridis', zorder=1)\n",
    "plt.scatter(centers[:, 0], centers[:, 1],c='black', s=300, alpha=0.6);\n",
    "\n",
    "w_factor = 0.2 / gmm.weights_.max()\n",
    "for pos, covar, w in zip(gmm.means_, gmm.covariances_, gmm.weights_):\n",
    "    draw_ellipse(pos, covar, alpha=w*.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "140a1b900e0d4419b0c6132e662a1bbceca80642"
   },
   "source": [
    "# GMM my implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3c2136591a6a20b2daa8d88608d3b0552f8ecd5e"
   },
   "outputs": [],
   "source": [
    "model = GMM(3, n_runs = 50)\n",
    "\n",
    "fitted_values = model.fit(Y_sklearn)\n",
    "predicted_values = model.predict(Y_sklearn)\n",
    "\n",
    "# # compute centers as point of highest density of distribution\n",
    "centers = np.zeros((3,2))\n",
    "for i in range(model.C):\n",
    "    density = mvn(cov=model.sigma[i], mean=model.mu[i]).logpdf(Y_sklearn)\n",
    "    centers[i, :] = Y_sklearn[np.argmax(density)]\n",
    "    \n",
    "plt.figure(figsize = (10,8))\n",
    "plt.scatter(Y_sklearn[:, 0], Y_sklearn[:, 1],c=predicted_values ,s=50, cmap='viridis', zorder=1)\n",
    "\n",
    "plt.scatter(centers[:, 0], centers[:, 1],c='black', s=300, alpha=0.5, zorder=2);\n",
    "\n",
    "w_factor = 0.2 / model.pi.max()\n",
    "for pos, covar, w in zip(model.mu, model.sigma, model.pi):\n",
    "    draw_ellipse(pos, covar, alpha = w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f86665c01cb82475cfcaca1964eecc84fd0a8e1f"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "44e78608d6065e138ce2f10d2b2b00a7374476f2"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
